{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b51bXrDkTLpa"
   },
   "source": [
    "# Lab 1: Introduction to OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPahAkrtTLpd"
   },
   "source": [
    "The goal of this first lab is to present a small introduction to image processing using OpenCV. In each section, you can find:\n",
    "* a small example - analyse the code and try it\n",
    "* some exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR1WSJtUTLpd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from opencv-python) (2.0.2)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Requirement already satisfied: numpy in /Users/andresilva/miniconda3/lib/python3.12/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Requirements for this tutorial\n",
    "#! pip install opencv-python\n",
    "#! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnzQcp25TLpe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in /Users/andresilva/miniconda3/lib/python3.12/site-packages (7.16.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (5.10.4)\n",
      "Requirement already satisfied: packaging in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (24.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (2.18.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (1.4.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbconvert) (5.14.3)\n",
      "Requirement already satisfied: webencodings in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jupyter-core>=4.7->nbconvert) (3.10.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbclient>=0.5.0->nbconvert) (7.4.9)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.10.6)\n",
      "Requirement already satisfied: entrypoints in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/andresilva/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.16.0)\n",
      "[NbConvertApp] Converting notebook 01-introduction.ipynb to script\n",
      "[NbConvertApp] Writing 6541 bytes to 01-introduction.py\n"
     ]
    }
   ],
   "source": [
    "# If you prefer, you can convert this notebook to a Python script by uncommenting the following command\n",
    "#! pip install nbconvert\n",
    "#! jupyter nbconvert --to script 01-introduction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UWhXnlHbTLpf"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataDir = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHKvYRR_TLpf"
   },
   "source": [
    "A reference table with some useful functions:\n",
    "\n",
    "| Function | Description |\n",
    "| ------------- | ------------- |\n",
    "| **Low-level NumPy** | |\n",
    "| `x = np.array(list)` | Converts Python list to `ndarray` |\n",
    "| `x = np.zeros((80, 80, 3))` | Create an array 80x80x3 of zeros (i.e., a black image). |\n",
    "| `x = np.ones((80, 80, 3))` | Same with ones. |\n",
    "| `x = np.random.rand((80, 80, 3))` | Same but each value is an uniform sample from [0,1]. |\n",
    "| `x = np.random.randn((80, 80, 3))` | Same but each value is a Gaussian sample from N(0,1). |\n",
    "| `print(x.shape)` | Print the shape of the `ndarray`. |\n",
    "| **Arithmetic** | |\n",
    "| `x[:, :, 0]` | Access the first slice of the third-axis (i.e., if `x` is an image with format BGR, this would be the blue channel. |\n",
    "| `x += 50` | Adds 50 to all pixels. |\n",
    "| `x[:, :, 1] *= 0.5` | Divides the green channel by 2. |\n",
    "| **OpenCV2 basic functions** | |\n",
    "| `img = cv2.imread(filename)` | Opens the image from the disk given by filename as a `ndarray`. |\n",
    "| `cv2.imwrite(filename, img)` | Save the given image in the disk with the given filename. |\n",
    "| `cv2.imshow(window_name, img)` | Open the given image in a window. |\n",
    "| `cv2.destroyWindow(window_name)` | Destroys the window. |\n",
    "| **OpenCV2 color conversion** | |\n",
    "| `cv2.cvtColor(img, cv2.COLOR_BGR2RGB)` | Converts the color format. |\n",
    "| `cv2.cvtColor(img, cv2.COLOR_BGR2HSV)` | |\n",
    "| `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)` | |\n",
    "| **OpenCV2 user interaction** | |\n",
    "| `cv2.setMouseCallback(window_name, callback)` | Calls the given callback function whenver user interacts with the window. |\n",
    "| `cv2.selectROI(window_name, img)` | Asks the user to select a part of the image and returns that. |\n",
    "| `key = cv2.waitKey(0)` | Waits until the user presses a key. |\n",
    "| `key = cv2.waitKey(delay)` | Wait until the user presses a key or a certain delay passes (in seconds). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ynRmTe_TLpf"
   },
   "source": [
    "### 1. Images – read, write and display; ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kVItIiOxTLpf"
   },
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Showing the image\n",
    "#cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Close the window after user pressed a key\n",
    "#cv2.destroyWindow(\"ml.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bx9fIosQTLpg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 380\n",
      "width: 308\n",
      "channels: 3\n"
     ]
    }
   ],
   "source": [
    "# Check image size\n",
    "h, w, c = img.shape\n",
    "print(f'height: {h}')\n",
    "print(f'width: {w}')\n",
    "print(f'channels: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wcpdDIy5TLpg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving image in bmp format\n",
    "cv2.imwrite('ml_new.bmp', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHjeFuu7TLpg"
   },
   "source": [
    "Exercise 1.1 - When the user moves the mouse, print the coordinate and RGB component of the pixel under the cursor. When the user clicks on a pixel, modify that pixel to blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NIlPBVRoTLpg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (250, 213) - RGB: (128, 131, 124)\n",
      "Coordinates: (237, 210) - RGB: (255, 255, 255)\n",
      "Coordinates: (202, 203) - RGB: (141, 160, 128)\n",
      "Coordinates: (197, 201) - RGB: (238, 252, 227)\n",
      "Coordinates: (181, 196) - RGB: (236, 247, 241)\n",
      "Coordinates: (170, 191) - RGB: (251, 255, 254)\n",
      "Coordinates: (167, 190) - RGB: (255, 255, 255)\n",
      "Coordinates: (155, 184) - RGB: (255, 255, 255)\n",
      "Coordinates: (150, 182) - RGB: (255, 255, 255)\n",
      "Coordinates: (148, 181) - RGB: (255, 255, 255)\n",
      "Coordinates: (144, 179) - RGB: (255, 255, 255)\n",
      "Coordinates: (143, 178) - RGB: (253, 253, 251)\n",
      "Coordinates: (142, 177) - RGB: (248, 248, 246)\n",
      "Coordinates: (141, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (141, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (141, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (147, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (153, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (169, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (176, 177) - RGB: (255, 255, 255)\n",
      "Coordinates: (191, 178) - RGB: (255, 255, 255)\n",
      "Coordinates: (205, 179) - RGB: (255, 255, 255)\n",
      "Coordinates: (217, 181) - RGB: (253, 253, 255)\n",
      "Coordinates: (232, 183) - RGB: (255, 211, 206)\n",
      "Coordinates: (238, 184) - RGB: (255, 253, 245)\n",
      "Coordinates: (246, 186) - RGB: (148, 145, 140)\n",
      "Coordinates: (249, 186) - RGB: (97, 93, 90)\n",
      "Coordinates: (251, 187) - RGB: (97, 99, 96)\n",
      "Coordinates: (251, 187) - RGB: (97, 99, 96)\n",
      "Coordinates: (252, 187) - RGB: (88, 92, 91)\n",
      "Coordinates: (252, 187) - RGB: (88, 92, 91)\n",
      "Coordinates: (252, 187) - RGB: (88, 92, 91)\n",
      "Coordinates: (252, 187) - RGB: (88, 92, 91)\n",
      "Coordinates: (251, 187) - RGB: (97, 99, 96)\n",
      "Coordinates: (251, 187) - RGB: (97, 99, 96)\n",
      "Coordinates: (251, 187) - RGB: (97, 99, 96)\n",
      "Coordinates: (250, 188) - RGB: (75, 81, 77)\n",
      "Coordinates: (250, 188) - RGB: (75, 81, 77)\n",
      "Coordinates: (249, 188) - RGB: (76, 83, 76)\n",
      "Coordinates: (249, 188) - RGB: (76, 83, 76)\n",
      "Coordinates: (248, 188) - RGB: (93, 98, 92)\n",
      "Coordinates: (248, 188) - RGB: (93, 98, 92)\n",
      "Coordinates: (248, 188) - RGB: (93, 98, 92)\n",
      "Coordinates: (248, 188) - RGB: (93, 98, 92)\n",
      "Coordinates: (248, 188) - RGB: (93, 98, 92)\n",
      "Coordinates: (247, 188) - RGB: (165, 168, 161)\n",
      "Coordinates: (246, 189) - RGB: (162, 165, 158)\n",
      "Coordinates: (246, 190) - RGB: (149, 154, 147)\n",
      "Coordinates: (245, 191) - RGB: (154, 155, 150)\n",
      "Coordinates: (245, 191) - RGB: (154, 155, 150)\n",
      "Coordinates: (244, 192) - RGB: (140, 141, 136)\n",
      "Coordinates: (244, 192) - RGB: (140, 141, 136)\n",
      "Coordinates: (244, 193) - RGB: (94, 96, 91)\n",
      "Coordinates: (244, 193) - RGB: (94, 96, 91)\n",
      "Coordinates: (244, 193) - RGB: (94, 96, 91)\n",
      "Coordinates: (244, 193) - RGB: (94, 96, 91)\n",
      "Coordinates: (244, 198) - RGB: (175, 176, 178)\n",
      "Coordinates: (239, 232) - RGB: (36, 36, 36)\n",
      "Coordinates: (230, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (231, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (232, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (233, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (234, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (236, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (236, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (237, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (238, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (238, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (239, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (239, 306) - RGB: (255, 255, 255)\n",
      "Coordinates: (240, 307) - RGB: (255, 255, 255)\n",
      "Coordinates: (241, 307) - RGB: (255, 255, 255)\n",
      "Coordinates: (242, 307) - RGB: (255, 255, 255)\n",
      "Coordinates: (243, 307) - RGB: (255, 255, 255)\n",
      "Coordinates: (244, 307) - RGB: (255, 255, 255)\n",
      "Coordinates: (249, 308) - RGB: (255, 255, 255)\n",
      "Coordinates: (252, 308) - RGB: (255, 255, 255)\n",
      "Coordinates: (256, 309) - RGB: (255, 255, 255)\n",
      "Coordinates: (273, 310) - RGB: (255, 255, 255)\n",
      "Coordinates: (283, 311) - RGB: (255, 255, 255)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "def mouse_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        # Get the pixel value at (x, y)\n",
    "        b, g, r = img[y, x]  # OpenCV uses BGR format\n",
    "        print(f\"Coordinates: ({x}, {y}) - RGB: ({r}, {g}, {b})\")\n",
    "    \n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Change the pixel color to blue\n",
    "        img[y, x] = [255, 0, 0]  # BGR for blue\n",
    "        cv2.imshow(\"Image\", img)\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.setMouseCallback(\"Image\", mouse_event)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Close the window after user pressed a key\n",
    "cv2.destroyWindow(\"ml.jpg\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1NcrwXhTLpg"
   },
   "source": [
    "Exercise 1.2 - Allow the user to select a region of interest (ROI) in the image, by clicking on two points that identify two opposite corners of the selected ROI, and save the ROI into another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1bVVMwRiTLpg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "First point: (39, 49)\n",
      "Second point: (278, 305)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "X, Y, W, H = cv2.selectROI(\"Image\", img)\n",
    "\n",
    "print(\"First point: ({}, {})\".format(X, Y))\n",
    "print(\"Second point: ({}, {})\".format(X + W, Y + H))\n",
    "\n",
    "rect= img[Y:Y+H, X:X+W]\n",
    "cv2.imshow(\"ROI\", rect)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"ROI\")\n",
    "#Close the window after user pressed a key\n",
    "\n",
    "cv2.imwrite(\"roi.bmp\",rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdgO75olTLph"
   },
   "source": [
    "### 2. Images – representation, grayscale and color, color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H8e3yIPuTLph"
   },
   "outputs": [],
   "source": [
    "# Create a white image\n",
    "m = np.ones((100,200,1), np.uint8)\n",
    "\n",
    "# Change the intensity to 100\n",
    "m = m * 100\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Grayscale image', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHU5-C5zTLph"
   },
   "outputs": [],
   "source": [
    "# Draw a line with thickness of 5 px\n",
    "cv2.line(m, (0,0), (100,200), 255, 5)\n",
    "cv2.line(m, (200, 0), (0, 100), 255, 5)\n",
    "cv2.imshow('Grayscale image with diagonals', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image with diagonals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06G15-MDTLph"
   },
   "source": [
    "Exercise 2.1 - Create a color image with 100(lines)x200(columns) pixels with yellow color. Then draw two diagonal lines across the image, one in red color, the other in blue color. Display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WdKl7PAOTLph"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m cv2\u001b[38;5;241m.\u001b[39mline(m, (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m), (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYellow image with diagonals\u001b[39m\u001b[38;5;124m'\u001b[39m, m) \n\u001b[0;32m---> 10\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyWindow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYellow image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "m= np.ones((100,200,3), np.uint8)\n",
    "\n",
    "m[:,:,0]=0\n",
    "m[:,:,1]=255\n",
    "m[:,:,2]=255\n",
    "cv2.line(m, (0,0), (200,100), (255,0,0), 5)\n",
    "cv2.line(m, (200, 0), (0, 100), (0,0,255), 5)\n",
    "cv2.imshow('Yellow image with diagonals', m) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Yellow image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKanX9raTLph"
   },
   "source": [
    "Exercise 2.2 - Read any color image, in RGB format, display it in one window, convert it to grayscale, display the grayscale image in another window and save the grayscale image to a different file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEfcSc2jTLph"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP4SVghlTLph"
   },
   "source": [
    "Exercise 2.3 - Split the 3 RGB channels and show each channel in a separate window. Add a constant value to one of the channels, merge the channels into a new color image and show the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01r33M-MTLph"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdGZ71FCTLph"
   },
   "source": [
    "Exercise 2.4 - Convert the image to HSV, split the 3 HSV channels and show each channel in a separate window. Add a constant value to the saturation channel, merge the channels into a new color image and show the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8JeNOPoTLph"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D0prQGmTLph"
   },
   "source": [
    "### 3. Video – acquisition and simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ie6PWPhWTLpi"
   },
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "frame_nr = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    # Wait for user to press s to save frame\n",
    "    if cv2.waitKey(1) == ord('s'):\n",
    "        frame_name = 'frame' + str(frame_nr) + '.png'\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        cv2.imshow(\"Saved frame: \" + frame_name, frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Saved frame: \" + frame_name)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nr += 1\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdeIXi61TLpi"
   },
   "source": [
    "Exercise 3.1 - Using the previous example as the baseline, implement a script that acquires the video from the webcam, converts it to grayscale, and shows the frames in binary format (i.e. the intensity of each pixel is 0 or 255); use a threshold value of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqFHHnXLTLpi"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCM4Tr73TLpi"
   },
   "source": [
    "Exercise 3.2 - Implement a simple detection/tracking algorithm for colored objects, using the following steps:\n",
    "1) take each frame of the video;\n",
    "2) convert from BGR to HSV color-space;\n",
    "3) threshold the HSV image for a range of color values (creating a binary mask);\n",
    "4) erase everything in the original image except the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQo-Btj6TLpi"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
